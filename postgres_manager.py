# postgres_manager.py (Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù‘Ù†Ø© Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ + Ø¯Ø¹Ù… cache_resource)
import logging
import os
import pandas as pd
import psycopg2
import pytz
from typing import Optional, Tuple
from sqlalchemy import create_engine
import streamlit as st
from dotenv import load_dotenv

from treasury_core.ports import HistoricalDataStore
import constants as C

load_dotenv()  # âœ… Ø¨Ø¹Ø¯ Ø§Ù„Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù…Ø¨Ø§Ø´Ø±Ø©

logger = logging.getLogger(__name__)


class PostgresDBManager(HistoricalDataStore):
    def __init__(self):
        self.conn_uri = os.environ.get("POSTGRES_URI")
        if not self.conn_uri:
            raise ValueError("Ù…ØªØºÙŠØ± Ø§Ù„Ø¨ÙŠØ¦Ø© POSTGRES_URI ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.")

        sqlalchemy_uri = self.conn_uri.replace(
            "postgres://", "postgresql+psycopg2://", 1
        )
        self.engine = create_engine(sqlalchemy_uri)

        self._init_db()

    def _get_connection(self):
        return psycopg2.connect(self.conn_uri)

    def _init_db(self) -> None:
        try:
            with self._get_connection() as conn:
                with conn.cursor() as cur:
                    cur.execute(
                        f"""
                        CREATE TABLE IF NOT EXISTS "{C.TABLE_NAME}" (
                            "{C.TENOR_COLUMN_NAME}" INTEGER NOT NULL,
                            "{C.YIELD_COLUMN_NAME}" REAL NOT NULL,
                            "{C.SESSION_DATE_COLUMN_NAME}" TEXT NOT NULL,
                            "{C.DATE_COLUMN_NAME}" TIMESTAMPTZ NOT NULL,
                            PRIMARY KEY ("{C.TENOR_COLUMN_NAME}", "{C.SESSION_DATE_COLUMN_NAME}")
                        );
                    """
                    )
            logger.info("âœ… PostgreSQL table initialized or already exists.")
        except psycopg2.Error:
            logger.error("âŒ PostgreSQL initialization failed", exc_info=True)
            raise

    def save_data(self, df: pd.DataFrame) -> None:
        df_to_save = df.copy()
        if "session_date_dt" in df_to_save.columns:
            df_to_save.drop(columns=["session_date_dt"], inplace=True)

        df_to_save[C.DATE_COLUMN_NAME] = pd.to_datetime(
            df_to_save[C.DATE_COLUMN_NAME], errors="coerce"
        )
        df_to_save = df_to_save[df_to_save[C.DATE_COLUMN_NAME].notnull()]
        if df_to_save.empty:
            logger.warning("âš ï¸ Ù„Ù… ÙŠØªÙ… Ø­ÙØ¸ Ø£ÙŠ Ø¨ÙŠØ§Ù†Ø§Øª: Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø²Ù…Ù†ÙŠØ© ØºÙŠØ± ØµØ§Ù„Ø­Ø©.")
            return

        if df_to_save[C.DATE_COLUMN_NAME].dt.tz is None:
            df_to_save[C.DATE_COLUMN_NAME] = df_to_save[
                C.DATE_COLUMN_NAME
            ].dt.tz_localize("UTC")
        else:
            df_to_save[C.DATE_COLUMN_NAME] = df_to_save[
                C.DATE_COLUMN_NAME
            ].dt.tz_convert("UTC")

        records = df_to_save.to_dict("records")

        try:
            with self._get_connection() as conn:
                with conn.cursor() as cur:
                    for row in records:
                        cur.execute(
                            f"""
                            INSERT INTO "{C.TABLE_NAME}" 
                            ("{C.TENOR_COLUMN_NAME}", "{C.YIELD_COLUMN_NAME}", "{C.SESSION_DATE_COLUMN_NAME}", "{C.DATE_COLUMN_NAME}")
                            VALUES (%s, %s, %s, %s)
                            ON CONFLICT ("{C.TENOR_COLUMN_NAME}", "{C.SESSION_DATE_COLUMN_NAME}")
                            DO UPDATE SET 
                                "{C.YIELD_COLUMN_NAME}" = EXCLUDED."{C.YIELD_COLUMN_NAME}",
                                "{C.DATE_COLUMN_NAME}" = EXCLUDED."{C.DATE_COLUMN_NAME}";
                        """,
                            (
                                row[C.TENOR_COLUMN_NAME],
                                row[C.YIELD_COLUMN_NAME],
                                row[C.SESSION_DATE_COLUMN_NAME],
                                row[C.DATE_COLUMN_NAME],
                            ),
                        )
            logger.info(f"ðŸ’¾ {len(df_to_save)} Ø³Ø¬Ù„ ØªÙ… Ø­ÙØ¸Ù‡ ÙÙŠ PostgreSQL.")
        except psycopg2.Error:
            logger.error("âŒ ÙØ´Ù„ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ PostgreSQL", exc_info=True)
            raise

    def clear_all_data(self) -> None:
        try:
            with self._get_connection() as conn:
                with conn.cursor() as cur:
                    cur.execute(f'TRUNCATE TABLE "{C.TABLE_NAME}" RESTART IDENTITY;')
            logger.info(f"ðŸ—‘ï¸ ØªÙ… Ù…Ø³Ø­ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ø¬Ø¯ÙˆÙ„: {C.TABLE_NAME}")
        except psycopg2.Error:
            logger.error("âŒ ÙØ´Ù„ ÙÙŠ Ù…Ø³Ø­ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† PostgreSQL", exc_info=True)
            raise

    def load_latest_data(
        self,
    ) -> Tuple[pd.DataFrame, Tuple[Optional[str], Optional[str]]]:
        try:
            with self.engine.connect() as conn:
                query = f"""
                    SELECT 
                        t."{C.TENOR_COLUMN_NAME}", 
                        t."{C.YIELD_COLUMN_NAME}", 
                        t."{C.SESSION_DATE_COLUMN_NAME}",
                        (SELECT MAX("{C.DATE_COLUMN_NAME}") FROM "{C.TABLE_NAME}") as max_scrape_date
                    FROM "{C.TABLE_NAME}" t
                    WHERE t."{C.DATE_COLUMN_NAME}" = (
                        SELECT MAX(t2."{C.DATE_COLUMN_NAME}") 
                        FROM "{C.TABLE_NAME}" t2 
                        WHERE t2."{C.TENOR_COLUMN_NAME}" = t."{C.TENOR_COLUMN_NAME}"
                    )
                """
                df = pd.read_sql_query(query, conn)

                if df.empty or "max_scrape_date" not in df.columns:
                    return pd.DataFrame(), ("Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ÙˆÙ„ÙŠØ©", None)

                max_date_raw = df["max_scrape_date"].iloc[0]
                if pd.isnull(max_date_raw):
                    return pd.DataFrame(), ("Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ÙˆÙ„ÙŠØ©", None)

                last_update_dt_utc = pd.to_datetime(max_date_raw, errors="coerce")
                if pd.isnull(last_update_dt_utc):
                    return pd.DataFrame(), ("Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ÙˆÙ„ÙŠØ©", None)

                if last_update_dt_utc.tzinfo is None:
                    last_update_dt_utc = last_update_dt_utc.tz_localize("UTC")
                else:
                    last_update_dt_utc = last_update_dt_utc.tz_convert("UTC")

                cairo_tz = pytz.timezone(C.TIMEZONE)
                last_update_dt_cairo = last_update_dt_utc.astimezone(cairo_tz)

                last_update_date = last_update_dt_cairo.strftime("%Y-%m-%d")
                last_update_time = last_update_dt_cairo.strftime("%I:%M %p")

                df.drop(columns=["max_scrape_date"], inplace=True)
                return df, (last_update_date, last_update_time)

        except Exception:
            logger.warning(
                "âš ï¸ Ù„Ù… ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø®ÙŠØ±Ø© Ù…Ù† PostgreSQL", exc_info=True
            )
            return pd.DataFrame(), ("Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£ÙˆÙ„ÙŠØ©", None)

    @st.cache_data
    def load_all_historical_data(_self) -> pd.DataFrame:
        """
        ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.
        ÙŠØªÙ… ØªØ®Ø²ÙŠÙ† Ù†ØªÙŠØ¬Ø© Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© Ù…Ø¤Ù‚ØªØ§Ù‹ Ù„ØªØ¬Ù†Ø¨ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.
        """
        try:
            with _self.engine.connect() as conn:
                query = f'SELECT * FROM "{C.TABLE_NAME}"'
                df = pd.read_sql_query(query, conn)

                if df.empty:
                    return pd.DataFrame()

                # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø¹Ù…ÙˆØ¯ Ø§Ù„ØªØ§Ø±ÙŠØ® Ù…Ù† Ù†ÙˆØ¹ datetime Ù‚Ø¨Ù„ Ø§Ù„ÙØ±Ø²
                df[C.DATE_COLUMN_NAME] = pd.to_datetime(df[C.DATE_COLUMN_NAME])
                return df.sort_values(by=C.DATE_COLUMN_NAME, ascending=False)

        except Exception:
            logger.error("âŒ ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ© Ù…Ù† PostgreSQL", exc_info=True)
            return pd.DataFrame()

    def get_latest_session_date(self) -> Optional[str]:
        try:
            with self._get_connection() as conn:
                with conn.cursor() as cur:
                    cur.execute(
                        f"""
                        SELECT "{C.SESSION_DATE_COLUMN_NAME}"
                        FROM "{C.TABLE_NAME}"
                        ORDER BY to_date("{C.SESSION_DATE_COLUMN_NAME}", 'DD/MM/YYYY') DESC
                        LIMIT 1;
                    """
                    )
                    result = cur.fetchone()
                    return result[0] if result else None
        except psycopg2.Error:
            logger.error("âŒ ÙØ´Ù„ ÙÙŠ Ø¬Ù„Ø¨ Ø¢Ø®Ø± ØªØ§Ø±ÙŠØ® Ø¬Ù„Ø³Ø© Ù…Ù† PostgreSQL", exc_info=True)
            return None


# âœ… ÙƒØ§Ø´ Ø³ØªØ±ÙŠÙ…Ù„ÙŠØª Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†Ø³Ø®Ø© ÙˆØ§Ø­Ø¯Ø© Ù…Ù† PostgreSQL manager
@st.cache_resource
def get_db_manager() -> HistoricalDataStore:
    """
    Ø¥Ø±Ø¬Ø§Ø¹ ÙƒØ§Ø¦Ù† PostgresDBManager Ù…Ø­Ù…ÙŠ Ø¨Ø§Ù„ÙƒØ§Ø´.
    """
    return PostgresDBManager()
